<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Gao&#39;s Happy Day</title>
    <link>https://gao377020481.github.io/post/</link>
    <description>Recent content in Posts on Gao&#39;s Happy Day</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://gao377020481.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Openmpi</title>
      <link>https://gao377020481.github.io/p/cmake/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/cmake/</guid>
      <description>Openmpi 初步使用 安装与测试 直接官网下载release包
wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.1.tar.gz linux下解压:
tar -zxf openmpi-4.1.1.tar.gz 进入开始configure： prefix 为指定安装路径
cd openmpi-4.1.1/ ./configure --prefix=/usr/local/openmpi 安装：
make sudo make install 设置环境变量
sudo vim /etc/profile 加入：
export PATH=/usr/local/openmpi/bin:$PATH export LD_LIBRARY_PATH=/usr/local/openmpi/lib:$LD_LIBRARY_PATH 生效：
source /etc/profile 测试
mpicc --version 写代码测试：hello.c
#include &amp;lt;stdio.h&amp;gt;#include &amp;#34;mpi.h&amp;#34; int main(int argc, char* argv[]) { int rank, size, len; char version[MPI_MAX_LIBRARY_VERSION_STRING]; MPI_Init(&amp;amp;argc, &amp;amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;amp;rank); MPI_Comm_size(MPI_COMM_WORLD, &amp;amp;size); MPI_Get_library_version(version, &amp;amp;len); printf(&amp;#34;Hello, world, I am %d of %d, (%s, %d)\n&amp;#34;, rank, size, version, len); MPI_Finalize(); return 0; } 编译并运行,我这里是四核虚拟机</description>
    </item>
    
    <item>
      <title>QUIC</title>
      <link>https://gao377020481.github.io/p/quic/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/quic/</guid>
      <description>QUIC
quick udp internet connection
是由 google 提出的使用 udp 进行多路并发传输的协议
优势 Quic 相比现在广泛应用的 http2+tcp+tls 协议有如下优势
 减少了 TCP 三次握手及 TLS 握手时间。 改进的拥塞控制。 避免队头阻塞的多路复用。 连接迁移。 前向冗余纠错。  0RTT建连 传输层和加密层总共只需要0RTT就可以建立连接。
因为其握手数据和HTTP数据一同发送，建连过程可以认为是0RTT的。
灵活的拥塞控制 QUIC默认使用了 TCP 协议的 Cubic 拥塞控制算法，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法。
但其：
可插拔  该拥塞控制算法实现于应用层，不需要修改内核就可以对其快速迭代 同一程序的不同连接使用不同拥塞控制算法，针对不同用户做适配 变更算法只需要修改配置再重新加载，不需要停机  递增的packet number和维持顺序的stream offset 使用严格递增的packet number，即使是相同包的重发也递增。接收端就可以区分开这个包是重发的还是之前的。
避免了在计算RTT的时候引发的歧义问题，因为发送方RTT计算需要计算的边界是包发出和包收到两处，如果使用重发包的时刻作为左边界，收到ack的时刻作为右边界，万一这个ack是初始发出的包的而不是重发的那就统计小了。
SACK选项空间更大 QUIC的SACK选项空间256Bytes 对比TCP的30Bytes很大，能够提供更多已经收到segment的信息，方便发送端进行精度更高的选择重传
Ack Delay Ack Delay是在接收端进行处理的时间，该时间也需要记录并发送，TCP的timestamp区域并不记录这个，计算的RTT理论上就更大不够准确。
QUIC在计算RTT时会减去Ack Delay
基于 stream 和 connecton 级别的流量控制 connection: TCP连接 ，复用：一个connection上可能有多个stream</description>
    </item>
    
    <item>
      <title>HTTP 1 to 2</title>
      <link>https://gao377020481.github.io/p/http-1-to-2/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/http-1-to-2/</guid>
      <description>HTTP/1.1 建连 输入网址
 有网址，无IP。所以先生成DNS查询报文，置于目的端口53的UDP报文中。目的地址就是建网时通过DHCP获得的DNS服务器IP。但是还无网关的MAC，所以使用ARP查询报文，其目的IP为网关IP，MAC地址为全1（广播）。网关收到后就通过ARP回答返回给客户机他自己的MAC地址。客户机拿到网关MAC就继续组装好DNS查询报文，发送给网关路由器。 DNS查询被网关转发到了最终DNS服务器，服务器查询到网址对应ip并返回给客户机。 客户机拿到IP就生成TCP套接字然后向IP所处机器发起连接请求，三次握手建立连接后向其发送HTTP GET报文。 网址服务器返回一个HTTP相应报文。 客户机拿到后浏览器渲染一下显示出来。  缺点   队头阻塞
  低效的 TCP 利用
  臃肿的消息首部
  受限的优先级设置
  HTTP2 </description>
    </item>
    
    <item>
      <title>Spectre&amp;Meltdown</title>
      <link>https://gao377020481.github.io/p/spectremeltdown/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/spectremeltdown/</guid>
      <description>Spectre&amp;amp;Meltdown
这是一种利用现代处理器特性来“窃取”内存中重要信息的漏洞。
Meltdown  诱使CPU在乱序执行的基础上将高权限的data信息放置于cache中  首先有一个数组，直接访问它的第data*4096个index处的元素 这样这个index处的元素会被放进cache中   循环遍历这个数组，当遍历到第data*4096个index处元素时，载入速度明显变快，这就说明这里是当时载入cache的元素 取到data*4096这个index就取到了data  假设data是一个内核内存空间内的数据，我们就get到了机密的内核数据，这都依赖于cpu的乱序执行：
exception(dont have priority to access))access(array[data*4096])乱序执行使得在指令生效前，access运行在了exception之前，虽然指令未生效（寄存器状态等未变），但cache内却有了array[data*4096]这个元素
Spectre Spectre基本原理与Meltdown类似，但他更强
Meltdown一旦被从根本上避免就无法使用，比如内核和用户使用不同的页目录寄存器等
Spectre并非依赖于乱序执行，而是依赖于分支预测。
分支预测也会使cpu提前跑一下cpu认为正确的分支，尽管他不一定真的是接下来要执行的，同样会在cache里留下痕迹。
但他要求代码有如下形式：
if(index1&amp;lt;array_a_size) {index2=array_a[index1];if(index2 &amp;lt; array_b_size);value = array_b[index2];}通过控制index1的长度，让array_b的特定下标的数据Cacheline被点亮，如果有办法访问一次array_b的全部内容，我们就可以窃取到index1这个值。</description>
    </item>
    
    <item>
      <title>STL</title>
      <link>https://gao377020481.github.io/p/stl/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/stl/</guid>
      <description>Alloc c++内存空间管理模块， 包含于:
&amp;lt;memory&amp;gt;:
 &amp;lt;stl_construct.h&amp;gt;: 定义全局函数construct(),destory()，负责对象析构与构造 &amp;lt;stl_alloc.h&amp;gt;: 定义一二级配置器，名为alloc &amp;lt;stl_uninitialized.h&amp;gt;: 一些全局函数用来操作大块内存数据  construct&amp;amp;destory construct类似C++的placement new。
destory存在两版本：
 版本一接收一指针参数，析构掉指针处的对象 版本二接收两指针参数，析构掉两指针之间的所有对象  alloc alloc空间配置器分一级配置器和二级配置器：
 一级配置器就是直接封装malloc和free 二级配置器：  维护16个自由链表组成内存池，分别负责十六种小型区块配置，填充内存池调用malloc 出现内存不足，或要求区块大于128Bytes转一级配置器    二级配置器：
 对于所需求区块无空闲块的情况直接去更大区块处查找，找到后出现的碎片会挂到与它大小匹配的区块链表上 都没有就分配40块需求区块，20块挂在链表上，20块作为后备  free free是如何知道对象的大小呢，这是因为malloc在分配内存时，会在对象的内存块的上下区域添加内存大小的cookie，VC6中malloc添加的是对象大小+1.不管怎么样，这都足够free去get到需要归还给操作系统的内存空间大小了，当然所谓归还也只是还给CRTL的内存池，只有空闲内存到达某种条件（例如整整几页的空间都空闲，他们可能还连续），那就使用系统调用来让内核释放掉这一块虚拟内存（其实也就是进task_struct里找到mm_sturct然后操作里面的bitmap，将要释放的内存对应的块设置为再次可用）。
Iterator  迭代器的根本还是一个指针，当然它是一种智能指针 通过指针萃取到指针所指对象的类型或一些其他信息很重要，这就是traits技法  分类上个侯捷老师的图：

traits 利用template自动推导和偏特化实现普遍可用的萃取特性方法，直接记录代码：
template &amp;lt;class T&amp;gt; struct MyIter { typedef T value_type; // 内嵌型别声明  T* ptr; MyIter(T* p = 0) : ptr(p) {} T&amp;amp; operator*() const { return *ptr; } }; // class type泛化版本 template &amp;lt;class T&amp;gt; struct iterator_traits { typedef typename T::value_type value_type; }; // 原生指针偏特化版本 template &amp;lt;class T&amp;gt; struct iterator_traits&amp;lt;T*&amp;gt; { typedef T value_type; }; // const对象指针偏特化版本 template &amp;lt;class T&amp;gt; struct iterator_traits&amp;lt;const T*&amp;gt; { typedef T value_type; }; template &amp;lt;class I&amp;gt; typename iterator_traits&amp;lt;I&amp;gt;::value_type //typename 告诉编译器这是一个type func(I ite) { std::cout &amp;lt;&amp;lt; &amp;#34;normal version&amp;#34; &amp;lt;&amp;lt; std::endl; return *ite; } 当然value_type只是常用的一种，STL还有其他几种，就不写了。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;对象</title>
      <link>https://gao377020481.github.io/p/c-%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/c-%E5%AF%B9%E8%B1%A1/</guid>
      <description>读书笔记：深度探索c++对象模型
C++ 对象模型 可用的对象模型有很多种，C++对象模型派生于简单对象模型，这里直接说C++对象模型：
 Non-static data member 存在于每一个object内 Static data member 存在于每一个object外 Static 与 Non-static function members 也被存放在所有object外 virtual function members：object内存在指向虚表vtb的指针（一般用于支持RTTI的type_info object的指针置于vtb第一个slot）  继承 虚继承 base class不管被继承多少次，永远只存在一个实体，虚继承产生的派生类只是有路径指向对应的base class实体。
这里的“路径”可以是类似虚表的指针（bptr）也可以是一系列指针，视存取效率而定。
然而，这样的话object的布局和大小会随着继承体系的改变而改变，所以这一部分的内容应被存放于对象模型的特殊部分。这个特殊部分就是“共享局部”，其他的固定不变的部分就是“不变局部”。所以为了实现虚继承，引入了两个局部的概念，虽然实现方式各编译器有所不同，但两个局部的概念一致。
构造 默认构造函数 如果没有user-declared constructor, 一个trivial 的constructor可能被生成， 但他啥都不干。
  只有编译器需要时，non-trivial 的constructor才会被编译器合成，但他也只干编译器需要的事情，比如A内有一个B类的成员（组合），B有一个构造函数，那么A也就需要一个non-trivial 的constructor，这个构造函数只会构造B，而不会管A内可能存在的其他成员。
  如果A内有B,C,D三个类的成员，这三个类都有自己的构造函数，显然编译器会为A生成一个构造函数，他会依次调用B,C,D的构造函数，顺序取决于三成员在A内的排列顺序。
  回到1，如果A内其他成员比如一个int值在user-declared constructor里初始化但是user-declared constructor内未初始化B，那编译器怎么办呢，编译器会扩写user-declared constructor，给里面加上个B的构造函数的调用。
  类内有虚函数存在，编译器需要扩张已有构造函数或生成一个构造函数来完成虚表的初始化操作
  虚继承的使用也会给构造函数增加工作量，编译器需要让构造函数给类添加执行期判断的能力，比如在派生类中添加一个bptr提供指向唯一基类实体的路径。
  默认拷贝构造函数 三种调用情况：
 X x1 = x2 变量赋值 f(x1) 函数传参 return x1 返回值  不需要默认拷贝构造函数：</description>
    </item>
    
    <item>
      <title>File System</title>
      <link>https://gao377020481.github.io/p/file-system/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/file-system/</guid>
      <description>JOS JOS不像其他操作系统一样在内核添加磁盘驱动，然后提供系统调用。我们实现一个文件系统进程来作为磁盘驱动。
 引入一个文件系统进程（FS进程）的特殊进程，该进程提供文件操作的接口,并被赋予io权限。（x86处理器使用EFLAGS寄存器的IOPL为来控制保护模式下代码是否能执行设备IO指令，比如in和out。） 建立RPC机制，客户端进程向FS进程发送请求，FS进程真正执行文件操作，并将数据返回给客户端进程。 更高级的抽象，引入文件描述符。通过文件描述符这一层抽象就可以将控制台，pipe，普通文件，统统按照文件来对待。（文件描述符和pipe实现原理） 支持从磁盘加载程序并运行。  结构 superblock
依然使用超级块来记录文件系统的元数据
file
File struct用来描述文件：文件名，大小，类型，保存文件内容的block号
tips: Directories与file结构相同，只是内容是一些file
Block Cache 在FS进程的虚拟内存空间中映射一段磁盘区域。
FS进程在创建时，set特殊的缺页处理函数。
当发生缺页中断时call那个缺页处理函数，从磁盘上把数据读入物理内存。
根据FS进程内存地址空间的映射关系，FS可以很方便的通过虚拟内存找到刚读入的数据在物理内存中的位置。
The Block Bitmap 磁盘块的是否使用的bitmap
The file system interface 文件系统建立好后，还需要通过ipc来构建供用户进程操作文件的API栈，课程的图拿来用一下：
 Regular env FS env+---------------+ +---------------+| read | | file_read || (lib/fd.c) | | (fs/fs.c) |...|.......|.......|...|.......^.......|...............| v | | | | RPC mechanism| devfile_read | | serve_read || (lib/file.c) | | (fs/serv.c) || | | | ^ || v | | | || fsipc | | serve || (lib/file.</description>
    </item>
    
    <item>
      <title>Preemptive Multitasking</title>
      <link>https://gao377020481.github.io/p/preemptive-multitasking/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/preemptive-multitasking/</guid>
      <description>JOS 多CPU支持 支持&amp;quot;symmetric multiprocessing&amp;quot; (SMP)， 启动阶段CPU分为BSP和AP，BSP负责初始化系统和启动操作系统，AP由BSP激活。哪一个CPU是BSP由硬件和BISO决定，到目前位置所有JOS代码都运行在BSP上。在SMP系统中，每个CPU都有一个对应的local APIC（LAPIC），负责传递中断。CPU通过内存映射IO(MMIO)访问它对应的APIC，这样就能通过访问内存达到访问设备寄存器的目的。BSP读取mp configuration table中保存的CPU信息，初始化cpus数组，ncpu（总共多少可用CPU），bootcpu指针（指向BSP对应的CpuInfo结构）。然后BSP通过在内存上写值向AP传递中断来启动其他cpu（为他们设置寄存器值等操作）。
CPU私有数据：1.内核栈 2.TSS 3.env 4.寄存器
显然以上私有数据都需要创建新的一份。
多CPU执行内核代码，需要锁来避免竞争，使用CAS机制实现一个内核锁就可以。当然这个粒度太大，在linux内核中有各种粒度的实现。
协作调度 实现yield函数由进程调用主动让出cpu，显然需要将yield注册为一项系统调用，由内核来真正的做切换进程的工作。这里的调度也就是最简单的FIFO。
fork 提供系统调用fork给用户创建进程的能力，fork()拷贝父进程的地址空间和寄存器状态到子进程。父进程从fork()返回的是子进程的进程ID，而子进程从fork()返回的是0。父进程和子进程有独立的地址空间，任何一方修改了内存，不会影响到另一方。
基于写时复制的原理，子进程只需要在一开始拷贝父进程的页目录就可以，当真正触发写操作的时候再在缺页处理函数里做真正的拷贝。因为用户进程中已经有拷贝需要的所有信息（物理页位置等），所以只需要在用户进程中调用用户进程自己的缺页处理函数就可以。所以：
 需要在进程fork的时候就设置新进程的缺页处理函数 同时fork的时候也要对页复制做对应处理（共享，写时复制，只读三种情况不同） 因为要在用户进程中处理异常，所以需要新建一个用户异常栈保存用于异常处理的函数需要的参数。 缺页中断发生时：trap()-&amp;gt;trap_dispatch()-&amp;gt;page_fault_handler() 这个page_fault_handler会进入汇编代码然后给用户异常栈赋好值再切换到用户栈，基于刚赋好的值，用户进程会直接执行真正的用户缺页处理函数，在这个却也处理函数里会判断是否因为写时复制导致的触发，是的话就拷贝这个物理页到新的地方然后建立虚拟地址到物理页的映射关系。 还有一点需要注意的是内核代码组织十分严格，所以默认内核态不会出现缺页异常，一旦出现可能内核被攻击了，所以在一开始page_fault_handler里需要判断由内核进程触发的话就要panic整个系统。  定时 外部时钟中断强制进入内核，内核判断当前周期到了没，可以将中断号+偏移量来控制时钟周期，到了就触发对应的处理函数。拿时间片轮转调度进程举例：在SMP上首先通过LAPIC来通知各个cpu然后让出进程。
IPC Inter-Process communication
进程间通信，这里进程间通信使用使两个进程的虚拟地址指向同一块物理页的机制来完成。调用recv的进程阻塞（让出cpu），调用send的进程陷入内核查找对应的recv进程，和其要接受到的虚拟地址，首先将要发送的物理地址找到，然后修改recv进程的要接受到的虚拟地址对应的页表项，将其映射到那个要发送的物理地址处。然后设置接收进程为就绪态等待内核调度。
Linux Kernel 涉及进程调度、锁、进程通信
进程调度 调度器 核心调度器
调度器的实现基于两个函数：周期性调度器函数和主调度器函数。这些函数根据现有进程的优先级分配CPU时间。这也是为什么整个方法称之为优先调度的原因。
a.主调度器函数 在内核中的许多地方，如果要将CPU分配给与当前活动进程不同的另一个进程，都会直接调用主调度器函数（schedule）。 主调度器负责将CPU的使用权从一个进程切换到另一个进程。周期性调度器只是定时更新调度相关的统计信息。cfs队列实际上是用红黑树组织的，rt队列是用链表组织的。
b.周期性调度器函数
周期性调度器在scheduler_tick中实现，如果系统正在活动中，内核会按照频率HZ自动调用该函数。该函数主要有两个任务如下：
 更新相关统计量：管理内核中与整个系统和各个进程的调度相关的统计量。其间执行的主要操作是对各种计数器加1。比如运行时间。 激活负责当前进程的调度类的周期性调度方法。  调度类
为方便添加新的调度策略，Linux内核抽象一个调度类sched_class，允许不同进程有针对性的选择调度算法。
运行队列
每个处理器有一个运行队列，结构体是rq。rq是描述就绪队列，其设计是为每一个CPU就绪队列，本地进程在本地队列上排序。cfs和rt。
调度进程
主动调度进程的函数是schedule() ，它会把主要工作委托给__schedule()去处理。
函数__shcedule的主要处理过程如下：
  调用pick_next_task()以选择下一个进程。
  调用context_switch()以切换进程。 调用context_switch：
  切换用户虚拟地址空间
  切换寄存器</description>
    </item>
    
    <item>
      <title>User Environments</title>
      <link>https://gao377020481.github.io/p/user-environments/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/user-environments/</guid>
      <description>JOS 这一部分做三件事：
 建立进程概念 异常处理，陷入内核 系统调用  进程和用户环境 JOS里进程是一个env结构，里面保存了简单的信息：页目录、寄存器缓存项（用于切换），连接指针（用于调度），状态等
首先提供基础设施：内核中保存进程的链表，这个数组需要初始化在物理内存上
显然创建一个进程，需要创建其对应的页目录，那就要在物理内存上分配对应的页目录和页表结构然后把他映射到虚拟内存里的页目录上。
要在进程上运行程序，就需要加载和解析ELF文件，同样分配物理页，载入elf文件各个segment，建立虚拟地址到物理地址的映射关系，然后修改寄存器的值为elf的entry。就可以运行起来elf上的程序了。
运行一个进程就只需要将进程结构内保存的寄存器值弹出到寄存器里。
trap与异常处理 一般来讲当异常发生，cpu会触发电信号，触发硬中断然后由中断控制器找到中断处理函数，但也有软中断的时候，通过指令提供的中断号结合IDT来查找到对应的中断处理函数。
中断发生，陷入内核，处理器根据TSS寄存器找到TSS结构，将栈寄存器SS和ESP分别设置为其中的SS0和ESP0两个字段的值，这样就切换到内核栈了
缺页异常与系统调用 缺页异常是一个中断，中断号是14，将这个号压入内核栈，然后call trap函数，在trap里dispatch到对应的处理函数就行。缺页的话就要分配物理页然后加载磁盘数据再建立映射关系，这一套操作目前由内核完成。
系统调用是一个中断，我们设置中断处理函数sys_call，并在trap内部根据传入的系统调用号做对应的dispatch到对应的系统调用处理。上面内核栈已经切换成功，其实cpu就在内核态了，接下来只需要压入触发系统调用对应的int指令需要的中断号和其它参数就可以call trap，然后dispatch到sys_call并传递参数（参数保存在一个trapframe结构中）。
Linux Kernel 进程 Linux内核把进程称为任务(task)，进程的虚拟地址空间分为用户虚拟地址空间和内核虚拟地址空间，所有进程共享内核虚拟地址空间，每个进程有独立的用户空间虚拟地址空间。
进程有两种特殊形式：没有用户虚拟地址空间的进程称为内核线程，共享用户虚拟地址空间的进程称为用户线程。通用在不会引起混淆的情况下把用户线程简称为线程。共享同一个用户虚拟地址空间的所有用户线程组成一个线程组。
四要素：
a.有一段程序供其执行。
b.有进程专用的系统堆栈空间。
c.在内核有task_struct数据结构。
d.有独立的存储空间，拥有专有的用户空间。
如果只具备前三条而缺少第四条，则称为“线程”。如果完全没有用户空间，就称为“内核线程”。而如果共享用户空间映射就称为“用户线程”。内核为每个进程分配一个task_struct结构时。实际分配两个连续物理页面(8192字节)，数据结构task_struct的大小约占1kb字节左右，进程的系统空间堆栈的大小约为7kb字节（不能扩展，是静态确定的）。</description>
    </item>
    
    <item>
      <title>Memory Management</title>
      <link>https://gao377020481.github.io/p/memory-management/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/memory-management/</guid>
      <description>内存管理
JOS JOS中主要是在做：
 线性地址到物理地址的映射（通过操作修改页表项实现） 在物理内存上划分出内核的页目录和页表存储区域并完成映射 保护模式的映射关系与段寄存器相关，32位的JOS通过段选择子找到段描述符，再解析段描述符的基地址，检查权限位后加上虚拟地址来实现 物理内存的分配在JOS内目前还无相应算法，只是单纯的连续分配  Linux kernel 自顶向下来看：
从glibc的malloc到mmap/brk/sbrk再到物理页的分配（buddy算法,内核中的slab，非连续页分配器）
当然拿C++来说，其STL用于容器的alloc分配器的实现，又是基于malloc的，使用开链数组来存放多个线性增长大小的空闲内存块，当有分配需要时一次申请多块（应该是20块）该大小内存。且找不到对应块时还具有相应的回收，拼接，查找功能。对于大块内存的分配使用单独的路径来分配和存储。分层分级分区的思路是各级内存分配器的惯用思路。
glibc 以ptmalloc为例：
malloc时，如果内存分配区（主，非主）真的无空间，调用mmap或brk/sbrk来在虚拟内存上取一块作为新的空间，mmap取得内存在mmap区域，brk/sbrk在heap上（在进程的描述符task_struct中的mm_struct里可以找到）。主分配区可以使用sbrk和mmap向os申请内存，而非分配区只能通过mmap向os申请内存。接下来os可能（因为mmap只是给一块虚拟地址，真实数据还未拷贝到物理内存上）要去物理内存上找可用区块然后将真实数据拷贝上去（用户触发缺页syscall），这里再涉及物理页的分配。
ptmalloc的内存管理方法就可以很好的解决每次要内存都要去向OS要的问题。它回收管理分配出的内存而不是每次都还给操作系统而是放入bin中留待下次使用，bin的整理等一些其他操作会在特定时候触发。
首先每个进程都有一个主分配区和几个非主分配区，分配区在多线程间共享，对分配区的操作需要加线程互斥锁。主分配区由一号或主线程拥有。
最小的内存管理单位为chunk，一段连续的内存被分成多个chunk，chunk内记录当前和前一个chunk的大小，用于合并。
下一层级是分配区中的bins，bins分为:
 fast bin: 保存小块的chunk bins: 2.1 unsorted bin： 是一个chunk缓冲区，这里的chunk都是在等待整理的chunk（释放或合并出来的），同时也有可能是即将被用得到的chunk，因为很多程序会频繁的分配释放相同大小的内存，它在fastbin里找不到就会直接来这里找，速度快。chunk的size 没有限制。 2.2 small bin： 类似alloc分配器的开链数组实现，大小小于512字节的chunk被称为small chunk，分级每个相差8KB放入small bin对应槽位。共62个不同大小的bin 2.3 large bin： 与small bin类似，只是其中存的是大chunk，且不单纯线性增长，共63个不同大小的bin  chunk的分配与释放是一个很复杂的管理流程，这里只说管理层级，不谈细致流程。
物理页分配 buddy 用户空间使用的最简单的物理页分配算法，直接分配连续的物理内存，然后回收能称为伙伴的空闲内存。 连续的物理页称为页块（page block），阶（order）是页的数量单位，2的n次方个连续页称为n阶页块。 如下条件的两个n阶页块称为伙伴（buddy）：
 两个页块是相邻的，即物理地址是连续的； 页块的第一页的物理面页号必须是2的n次方的整数倍； 如果合并（n+1）阶页块，第一页的物理页号必须是2的括号(n+1)次方的整数倍。  分配的基本单位是n阶页块，不存在的话就去更高阶找，找到后拆开，都找不到就要使用非连续页分配机制，多次调用更低阶的页块分配
物理内存首先被分为不同zone，并对zone维护一个使用率，根据区域水线来决定是否从其他区域借用物理页。
a. 高水线（HIGH）：如果内存区域的空闲页数大于高水线，说明该内存区域的内存充足。
b. 低水线（LOW）：如果内存区域的空闲页数小于低水线，说明该内存区域的内存轻微不足。
c. 最低水线（MIN）：如果内存区域空闲页数小于最低水线，说明该内存区域的内存严重不足。
通用页分配入口
__alloc_pages_nodemask
slab（内核使用） slab分配器的作用不仅仅是分配小块内存，更重要的作用是针对经常分配和释放的对象充当缓存。slab分配器的 核心思路是：为每种对象类型创建一个内存缓存，每个内存缓存由多个大块组成，一个大块是由一个或多个连 续的物理页，每个大块包含多个对象。slab采用面向对象的思想，基于对象类型管理内存，每种对象被划分为一 类，比如进程描述符task_struct是一个类，每个进程描述符实例是一个对象。</description>
    </item>
    
    <item>
      <title>Boot</title>
      <link>https://gao377020481.github.io/p/boot/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/boot/</guid>
      <description>以MIT6.828的分节方式来记录操作系统的笔记。
所以第一章： Boot 启动
JOS 在JOS里，Boot作为Lab1存在。
实模式下运行BIOS，BIOS设置eip以启动bootloader，boot loader检查系统状态，开启保护模式，将磁盘上的kernel加载入物理内存，设置eip启动kernel。Kernel开启分页。
BIOS BIOS的启动依赖于硬件的电信号，在qemu虚拟机里模拟了这样一个信号来启动BIOS。
Bootloader Bootloader：
 从实模式进入保护模式，加载全局描述符表（虚拟地址到线性（物理地址）的映射开启） 从磁盘加载kernel到内存（通过读取ELF文件的方式）  Kernel 进入Kernel后：
 开启分页（就是在物理内存的特定位置创建内核页目录和页表数组，实现线性地址到物理地址的映射关系） 这里还基于内存映射的关系，实现了向IO HOLE区域（VGA显存）写值的功能，得以在终端上输出了字符  Linux kernel 在linux kernel中，这一环节的基本流程很相似，参考深入理解Linux内核附录1记录一个很简要的流程：
BIOS 硬件电信号拉起ROM上的BIOS程序，BIOS启动后简单检查和初始化一下硬件，随后在磁盘扇区上搜索操作系统来启动，找到磁盘第一个扇区（引导扇区）后将其拷贝到物理内存的0X00007C00处。
Bootloader 物理内存上有bootloader的第一部分了，第一部分可能会移动他的位置并将第二部分再装入物理内存的特定位置，第二部分会从磁盘中读取OS的映射表，提供给用户选项，选择启动哪一个操作系统，选中后bootloader就会调用BIOS过程来不停的装载内核映像，其中setup()函数在0X00090200处，下一步会跳转到这里
setup() 初始化硬件、和一些寄存器等，并跳转到startup_32()
startup_32() 初始化临时堆栈，段寄存器并解压内核映像放置到物理内存上，然后跳转到内核映像上启动
解压的内核映像启动点仍是一个叫做startup_32()的函数，它会再检查一下硬件软件信息然后的跳转到start_kernel()函数
start_kernel() 完成linux内核初始化工作，具体工作过多，这里不说</description>
    </item>
    
    <item>
      <title>Mysql</title>
      <link>https://gao377020481.github.io/p/mysql/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/mysql/</guid>
      <description>视图 视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。其内容由查询定义。 基表：用来创建视图的表叫做基表。 通过视图，可以展现基表的部分数据。 视图数据来自定义视图的查询中使用的表，使用视图动态生成。
优点  简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。 安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。 数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。  CREATEVIEW&amp;lt;视图名&amp;gt;AS&amp;lt;SELECT语句&amp;gt;触发器 触发器（trigger）是MySQL提供给程序员和数据分析员来保证数据完整性的一种方法，它是与表事件相关的特殊的存储过程，它的执行不是由程序调用，也不是手工启动，而是由事件来触发，比如当对一个表进行DML操作（ insert ， delete ， update ）时就会激活它执行。
监视对象： table
监视事件： insert 、 update 、 delete
触发时间： before ， after
触发事件： insert 、 update 、 delete
CREATETABLE`work`(`id`INTPRIMARYKEYauto_increment,`address`VARCHAR(32))DEFAULTcharset=utf8ENGINE=INNODB;CREATETABLE`time`(`id`INTPRIMARYKEYauto_increment,`time`DATETIME)DEFAULTcharset=utf8ENGINE=INNODB;CREATETRIGGERtrig_test1AFTERINSERTON`work`FOREACHROWINSERTINTO`time`VALUES(NULL,NOW());存储过程 SQL语句需要先编译然后执行，而存储过程（Stored Procedure）是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给定参数（如果该存储过程带有参数）来调用执行它。
存储过程是可编程的函数，在数据库中创建并保存，可以由SQL语句和控制结构组成。当想要在不同的应用程序或平台上执行相同的函数，或者封装特定功能时，存储过程是非常有用的。数据库中的存储过程可以看做是对编程中面向对象方法的模拟，它允许控制数据的访问方式。
优点  能完成较复杂的判断和运算 有限的编程 可编程行强，灵活 SQL编程的代码可重复使用 执行的速度相对快一些 减少网络之间的数据传输，节省开销  CREATEPROCEDURE过程名([[IN|OUT|INOUT]参数名数据类型[,[IN|OUT|INOUT]参数名数据类型…]])[特性...]过程体存储过程根据需要可能会有输入、输出、输入输出参数，如果有多个参数用&amp;quot;,&amp;ldquo;分割开。
MySQL 存储过程的参数用在存储过程的定义，共有三种参数类型 IN , OUT , INOUT 。
IN ：参数的值必须在调用存储过程时指定，0在存储过程中修改该参数的值不能被返回，可以设置默认值
OUT ：该值可在存储过程内部被改变，并可返回
INOUT ：调用时指定，并且可被改变和返回
过程体的开始与结束使用 BEGIN 与 END 进行标识。</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>https://gao377020481.github.io/p/redis/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/redis/</guid>
      <description>Redis
Remote Dictionary Service， 远程字典服务，内存式数据库，非关系型，KV结构
三张网图描述redis基本数据结构：   
数据与编码 String 字符数组，该字符串是动态字符串，字符串长度小于1M时，加倍扩容；超过1M每次只多扩1M；字符串最大长度为512M；
Tips：redis字符串是二进制安全字符串；可以存储图片，二进制协议等二进制数据；
 字符串长度小于等于 20 且能转成整数，则使用 int 存储； 字符串长度小于等于 44，则使用 embstr 存储； 字符串长度大于 44，则使用 raw 存储；  44为界
首先说明redis以64字节作为大小结构分界点，但其sdshdr和redisobject结构会占用一些空间，所以真正保存数据的大小小于64字节
旧版本使用39为界，新版本使用44为界，这是因为旧版本中sdshdr占用8字节目前的sdshdr8是针对小结构的优化（大结构使用shshdr16，64），仅占用3字节，节省了5字节空间。所以新版本以44为界。
raw和embstr
raw 编码会调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构， 而 embstr 编码则通过调用一次内存分配函数来分配一块连续的空间存储两结构
embstr使用连续内存，更高效的利用缓存，且一次内存操作带来了更好的创建和销毁效率
操作方式与转换
  以一个浮点数的value作为例子，浮点数会被转换成字符串然后存储到数据库内。如果要对V进行操作，他也会先从字符串转换为浮点数然后再进行操作。
  以一个整数2000的value作为例子，该数会被保存为int但使用append进行追加一个字符串“is a good number！”后， 该值会被转换为embstr， 然而embstr的对象从redis视角看来是只读的（未实现操作embstr的方法）， 所以该对象又会被转换raw然后实行相应操作并保存为raw
  List 双向链表，很容易理解，但其node有讲究（压缩时使用ziplist）
列表中数据是否压缩的依据：
 元素长度小于 48，不压缩； 元素压缩前后长度差不超过 8，不压缩；  直接放数据结构，然后分析:</description>
    </item>
    
    <item>
      <title>异常处理</title>
      <link>https://gao377020481.github.io/p/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid>
      <description>Try Catch组件实现 先说明try catch组件使用setjump和longjump实现
setjump longjump语法 jmp_buf env;环境
setjump(env)设置回跳点，返回longjump(env,out)传的参数out，配套使用，longjump可穿越函数跳转
jmp_buf env; int c = setjump(env); longjump(env,3); 这里longjump后就会跳回setjump这一行，并且setjump会返回3，也就是c = 3。
int count = 0; jmp_buf env; void a(int indx) { longjump(env,indx); } int main() { int idx = 0; count = setjump(env); if(count == 0) { a(env,idx++); } else if (count == 1) { a(env,idx++); } else { printf(&amp;#34;ok&amp;#34;); } return 0; } 如上，函数a会调回开头setjump处，如果是这样a调用多次，a又没有返回（a运行到longjump处进入了，没返回），a的栈会不会还存在，存在的话如果有无数个a，会不会发生栈溢出。
答案是不会，因为a在进入longjump后，其栈指针直接失效，a的栈直接失效，在setjump函数所在函数block中被覆盖，所以a的多次调用不会发生栈溢出。
setjump 与 longjump本身是线程安全的
setjump longjump与try catch的关系 先来个 代码：</description>
    </item>
    
    <item>
      <title>线程池进阶版</title>
      <link>https://gao377020481.github.io/p/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%BF%9B%E9%98%B6%E7%89%88/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%BF%9B%E9%98%B6%E7%89%88/</guid>
      <description>#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;string.h&amp;gt; #include &amp;lt;pthread.h&amp;gt; #define LL_ADD(item, list) do { \ item-&amp;gt;prev = NULL;	\ item-&amp;gt;next = list;	\ list = item;	\ } while(0)  #define LL_REMOVE(item, list) do {	\ if (item-&amp;gt;prev != NULL) item-&amp;gt;prev-&amp;gt;next = item-&amp;gt;next;	\ if (item-&amp;gt;next != NULL) item-&amp;gt;next-&amp;gt;prev = item-&amp;gt;prev;	\ if (list == item) list = item-&amp;gt;next;	\ item-&amp;gt;prev = item-&amp;gt;next = NULL;	\ } while(0)  typedef struct NWORKER {//工作线程信息 	pthread_t thread; //线程id 	int terminate; //是否要终止 	struct NWORKQUEUE *workqueue; //线程池，用于找到工作队列 	struct NWORKER *prev; struct NWORKER *next; } nWorker; typedef struct NJOB { //工作个体 	void (*job_function)(struct NJOB *job); void *user_data; struct NJOB *prev; struct NJOB *next; } nJob; typedef struct NWORKQUEUE { struct NWORKER *workers; //所有工作线程的链表 	struct NJOB *waiting_jobs; //工作队列 	pthread_mutex_t jobs_mtx; pthread_cond_t jobs_cond; } nWorkQueue; typedef nWorkQueue nThreadPool; static void *ntyWorkerThread(void *ptr) { //工作线程取用工作 	nWorker *worker = (nWorker*)ptr; while (1) { pthread_mutex_lock(&amp;amp;worker-&amp;gt;workqueue-&amp;gt;jobs_mtx); //先获取工作队列的操作互斥锁  while (worker-&amp;gt;workqueue-&amp;gt;waiting_jobs == NULL) { if (worker-&amp;gt;terminate) break; pthread_cond_wait(&amp;amp;worker-&amp;gt;workqueue-&amp;gt;jobs_cond, &amp;amp;worker-&amp;gt;workqueue-&amp;gt;jobs_mtx); //如果工作队列为空，这个线程就阻塞在条件变量上等待事件发生 	} if (worker-&amp;gt;terminate) { pthread_mutex_unlock(&amp;amp;worker-&amp;gt;workqueue-&amp;gt;jobs_mtx); //如果检测到工作线程被终止，那么这个线程就需要结束工作，但在结束工作前需要将对工作队列的取用权限放开，所以这里在break前需要解锁这个互斥锁 	break; } nJob *job = worker-&amp;gt;workqueue-&amp;gt;waiting_jobs; //从工作队列中获取一个工作 	if (job !</description>
    </item>
    
    <item>
      <title>线程池</title>
      <link>https://gao377020481.github.io/p/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</guid>
      <description>线程池 基本功能模块：  线程池创建函数 线程池删除函数 线程池回调函数 线程池添加函数 线程池数据结构 线程任务数据结构 线程本身数据结构（由pid唯一确认）  首先实现数据结构： 线程任务数据结构：
struct nTask { void (*task_func)(struct nTask *task); void *user_data; struct nTask *prev; struct nTask *next; }; 这是任务中的一个个体，任务队列头存储在线程池数据结构中 void (*task_func)(struct nTask *task)函数指针表明函数为task_func且参数为struct nTask， 参数若为void是否更好
线程本身数据结构：
struct nWorker { pthread_t threadid; int terminate; struct nManager *manager; struct nWorker *prev; struct nWorker *next; }; pid唯一标识线程，terminate用于标识该线程应被删除，存储manager（也就是所属线程池）是为了通过manager找到task队列以获取task
线程池数据结构：
typedef struct nManager { struct nTask *tasks; struct nWorker *workers; pthread_mutex_t mutex; pthread_cond_t cond; } ThreadPool; 可以看到线程池其实只是一个管理者，使用mutex控制各个线程对进程内公共资源的访问，保证同时只有一个线程在访问公共资源，cond来控制各个线程的状态（处于等待队列（阻塞）或可以运行（运行、就绪态））细节在回调函数中</description>
    </item>
    
    <item>
      <title>Reactor</title>
      <link>https://gao377020481.github.io/p/reactor/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/reactor/</guid>
      <description>Reactor  组成：⾮阻塞的io + io多路复⽤； 特征：基于事件循环，以事件驱动或者事件回调的⽅式来实现业务逻辑； 表述：将连接的io处理转化为事件处理；  单Reactor 
代表：redis 内存数据库 操作redis当中的数据结构 redis 6.0 多线程
单reactor模型 + 任务队列 + 线程池 
代表：skynet
多Reactor 
应⽤： memcached accept(fd, backlog) one eventloop per thread
 多进程应用  
应⽤：nginx
多reactor + 消息队列 + 线程池 </description>
    </item>
    
    <item>
      <title>定时器</title>
      <link>https://gao377020481.github.io/p/%E5%AE%9A%E6%97%B6%E5%99%A8/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E5%AE%9A%E6%97%B6%E5%99%A8/</guid>
      <description>定时器 定时器作用很多，常见于心跳检测，冷却等等 实现时区别主要在于定时器队列的管控（排序）
基本方案： 红黑树： 使用红黑树对定时器排序，排序依据为定时器过期时间，每隔单位时间检查红黑树中最小时间是否小于等于当前时间，如果小于等于就删除节点并触发节点的callback。时间复杂度增删O(logn)，Nginx使用红黑树。删除添加操作自旋。
最小堆： 最小堆根节点最小，直接拿出根节点与当前时间比较即可，删除操作将根节点与末尾节点对换并删除末尾节点然后将新的根节点下沉，添加时加入末尾节点并上升。
时间轮：  时间轮可以分为单层级与多层级。简单的单层级时间轮使用初始化好的链表数组来存储对应的事件节点链表，时间数据结构中一般包含引用计数，该数据结构只有在引用计数置零后销毁，一般也代表着事件对应的资源可以释放。单层时间轮的大小至少需要大于最长定时时间/单位时间，举例：每5秒发送一个心跳包，连接收到心跳包时需要开启一个10秒的定时器并将事件引用计数加一（事件数据结构插入链表数组中10秒后的链表中），也就是最长定时10秒，10秒后检查该连接对应的事件并将引用计数减一，如果减一后为0就说明连接超时，释放所有资源，关闭事件。在该例子中，初始化的链表数组大小至少为11，因为假如在第0秒来一个心跳包，我们就需要在第10号位置将该连接对应的事件节点加入事件链表中，如果小于11，比如为8，那从0开始往后10个的位置就是在2号位置，那2秒后就得触发了，这与我们设置的10秒定时时间不一致。

代码实现： 红黑树： 红黑树数据结构直接使用nginx自带的rbtree头文件，就不自己写了
红黑树定时器头文件： #ifndef _MARK_RBT_ #define _MARK_RBT_  #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdint.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;stddef.h&amp;gt; #if defined(__APPLE__) #include &amp;lt;AvailabilityMacros.h&amp;gt;#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;mach/task.h&amp;gt;#include &amp;lt;mach/mach.h&amp;gt;#else #include &amp;lt;time.h&amp;gt;#endif  #include &amp;#34;rbtree.h&amp;#34; ngx_rbtree_t timer; static ngx_rbtree_node_t sentinel; typedef struct timer_entry_s timer_entry_t; typedef void (*timer_handler_pt)(timer_entry_t *ev); struct timer_entry_s { ngx_rbtree_node_t timer; timer_handler_pt handler; }; static uint32_t current_time() { uint32_t t; #if !defined(__APPLE__) || defined(AVAILABLE_MAC_OS_X_VERSION_10_12_AND_LATER) 	struct timespec ti; clock_gettime(CLOCK_MONOTONIC, &amp;amp;ti); t = (uint32_t)ti.</description>
    </item>
    
    <item>
      <title>进阶TCP服务器</title>
      <link>https://gao377020481.github.io/p/%E8%BF%9B%E9%98%B6tcp%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E8%BF%9B%E9%98%B6tcp%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>进阶TCP服务器 该模块涉及TCP服务器常见点：并发量、IO模型
IO网络模型 阻塞IO （Blocking IO） 
阻塞IO的情况下，我们如果需要更多的并发，只能使用多线程，一个IO占用一个线程，资源浪费很大但是在并发量小的情况下性能很强。
非阻塞IO （Non-Blocking IO） 
在非阻塞状态下，recv() 接口在被调用后立即返回，返回值代表了不同的含义。如在本例中，
 recv() 返回值大于 0，表示接受数据完毕，返回值即是接受到的字节数； recv() 返回 0，表示连接已经正常断开； recv() 返回 -1，且 errno 等于 EAGAIN，表示 recv 操作还没执行完成； recv() 返回 -1，且 errno 不等于 EAGAIN，表示 recv 操作遇到系统错误 errno。  非阻塞的接口相比于阻塞型接口的显著差异在于，在被调用之后立即返回。使用如下的函数可以将某句柄 fd 设为非阻塞状态：
fcntl( fd, F_SETFL, O_NONBLOCK ); 多路复用IO （IO Multiplexing） 
多路复用IO，select/poll、epoll。
select/poll select和poll很相似，在检测IO时间的时候都需要遍历整个FD存储结构，只是select使用数组存储FD，其具有最大值限制，而poll使用链表无最大值限制（与内存大小相关）。
先来分析select的优缺点，这样就知道epoll相比select的优势等。
select 本质上是通过设置或检查存放fd标志位的数据结构进行下一步处理。 这带来缺点： 单个进程可监视的fd数量被限制，即能监听端口的数量有限 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试 一般该数和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认1024个，64位默认2048。
当socket较多时，每次select都要通过遍历FD_SETSIZE个socket，不管是否活跃，这会浪费很多CPU时间。如果能给 socket 注册某个回调函数，当他们活跃时，自动完成相关操作，即可避免轮询，这就是epoll与kqueue。
select 调用流程</description>
    </item>
    
    <item>
      <title>设计模式</title>
      <link>https://gao377020481.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      <description>设计模式 首先先上所有设计模式的原则，这些原则贯彻于每一种设计模式中，是各种设计模式的根
原则   依赖倒置原则
 高层模块不应该依赖低层模块，⼆者都应该依赖抽象。 抽象不应该依赖具体实现，具体实现应该依赖于抽象。    开放封闭原则
 ⼀个类应该对扩展开放，对修改关闭。    面向接口编程
 不将变量类型声明为某个特定的具体类，而是声明为某个接⼝。 客户程序无需获知对象的具体类型，只需要知道对象所具有的接口。 减少系统中各部分的依赖关系，从而实现“高内聚、松耦合”的类型设计⽅案。    封装变化点
 将稳定点和变化点分离，扩展修改变化点；让稳定点与变化点的实现层次分离。    单一职责原则
 ⼀个类应该仅有⼀个引起它变化的原因。    里氏替换原则
 子类型必须能够替换掉它的父类型；主要出现在⼦类覆盖父类实现，原来使用父亲类型的程序可能出现错误；覆盖了父类方法却没实现父类方法的职责；    接口隔离原则
 不应该强迫客户依赖于他们不用的方法。 ⼀般用于处理⼀个类拥有比较多的接口，而这些接口涉及到很多职责    对象组合优于类继承
 继承耦合度⾼，组合耦合度低    模板模式 
首先，先提下使用到的原则：
 依赖倒置原则 单一职责原则 接口隔离原则  定义： 定义⼀个操作中的算法的骨架 ，⽽将⼀些步骤延迟到子类中。 Template Method使得子类可以不 改变⼀个算法的结构即可重定义该算法的某些特定步骤。</description>
    </item>
    
    <item>
      <title>连接池</title>
      <link>https://gao377020481.github.io/p/%E8%BF%9E%E6%8E%A5%E6%B1%A0/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E8%BF%9E%E6%8E%A5%E6%B1%A0/</guid>
      <description>连接池实现 mysql连接池 头文件： #ifndef DBPOOL_H_ #define DBPOOL_H_  #include &amp;lt;iostream&amp;gt;#include &amp;lt;list&amp;gt;#include &amp;lt;mutex&amp;gt;#include &amp;lt;condition_variable&amp;gt;#include &amp;lt;map&amp;gt;#include &amp;lt;stdint.h&amp;gt; #include &amp;lt;mysql.h&amp;gt; #define MAX_ESCAPE_STRING_LEN	10240  using namespace std; // 返回结果 select的时候用 class CResultSet { public: CResultSet(MYSQL_RES* res); virtual ~CResultSet(); bool Next(); int GetInt(const char* key); char* GetString(const char* key); private: int _GetIndex(const char* key); MYSQL_RES* m_res; MYSQL_ROW	m_row; map&amp;lt;string, int&amp;gt;	m_key_map; }; // 插入数据用 class CPrepareStatement { public: CPrepareStatement(); virtual ~CPrepareStatement(); bool Init(MYSQL* mysql, string&amp;amp; sql); void SetParam(uint32_t index, int&amp;amp; value); void SetParam(uint32_t index, uint32_t&amp;amp; value); void SetParam(uint32_t index, string&amp;amp; value); void SetParam(uint32_t index, const string&amp;amp; value); bool ExecuteUpdate(); uint32_t GetInsertId(); private: MYSQL_STMT*	m_stmt; MYSQL_BIND*	m_param_bind; uint32_t	m_param_cnt; }; class CDBPool; class CDBConn { public: CDBConn(CDBPool* pDBPool); virtual ~CDBConn(); int Init(); // 创建表 	bool ExecuteCreate(const char* sql_query); // 删除表 	bool ExecuteDrop(const char* sql_query); // 查询 	CResultSet* ExecuteQuery(const char* sql_query); /** * 执行DB更新，修改 * * @param sql_query sql * @param care_affected_rows 是否在意影响的行数，false:不在意；true:在意 * * @return 成功返回true 失败返回false */ bool ExecuteUpdate(const char* sql_query, bool care_affected_rows = true); uint32_t GetInsertId(); // 开启事务 	bool StartTransaction(); // 提交事务 	bool Commit(); // 回滚事务 	bool Rollback(); // 获取连接池名 	const char* GetPoolName(); MYSQL* GetMysql() { return m_mysql; } private: CDBPool* m_pDBPool;	// to get MySQL server information 	MYSQL* m_mysql;	// 对应一个连接 	char	m_escape_string[MAX_ESCAPE_STRING_LEN + 1]; }; class CDBPool {	// 只是负责管理连接CDBConn，真正干活的是CDBConn public: CDBPool() {} CDBPool(const char* pool_name, const char* db_server_ip, uint16_t db_server_port, const char* username, const char* password, const char* db_name, int max_conn_cnt); virtual ~CDBPool(); int Init();	// 连接数据库，创建连接 	CDBConn* GetDBConn(const int timeout_ms = -1);	// 获取连接资源 	void RelDBConn(CDBConn* pConn);	// 归还连接资源  const char* GetPoolName() { return m_pool_name.</description>
    </item>
    
    <item>
      <title>内存池</title>
      <link>https://gao377020481.github.io/p/%E5%86%85%E5%AD%98%E6%B1%A0/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E5%86%85%E5%AD%98%E6%B1%A0/</guid>
      <description>内存池实现（注释详细） #include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;unistd.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; #define MP_ALIGNMENT 32 //对齐信息 #define MP_PAGE_SIZE	4096 //单次分配大块大小 #define MP_MAX_ALLOC_FROM_POOL	(MP_PAGE_SIZE-1)  #define mp_align(n, alignment) (((n)+(alignment-1)) &amp;amp; ~(alignment-1)) #define mp_align_ptr(p, alignment) (void *)((((size_t)p)+(alignment-1)) &amp;amp; ~(alignment-1))  struct mp_large_s { struct mp_large_s *next; void *alloc; }; // 当单次分配超过pagesize时就需要一次分配然后归入large的一个链表中保存  struct mp_node_s { unsigned char *last; unsigned char *end; struct mp_node_s *next; size_t failed; };// 页，用于小块的分配,last指向页内使用到的位置  struct mp_pool_s { size_t max; struct mp_node_s *current; struct mp_large_s *large; struct mp_node_s head[0]; }; //内存池  struct mp_pool_s *mp_create_pool(size_t size); void mp_destory_pool(struct mp_pool_s *pool); void *mp_alloc(struct mp_pool_s *pool, size_t size); void *mp_nalloc(struct mp_pool_s *pool, size_t size); void *mp_calloc(struct mp_pool_s *pool, size_t size); void mp_free(struct mp_pool_s *pool, void *p); //首先需要明确，在分配的时候需要将所有的数据结构都存在我们管理的内存池中 //比如struct mp_pool_s *pool这个内存池本身也需要受我们管理 struct mp_pool_s *mp_create_pool(size_t size) { struct mp_pool_s *p; int ret = posix_memalign((void **)&amp;amp;p, MP_ALIGNMENT, size + sizeof(struct mp_pool_s) + sizeof(struct mp_node_s)); //posix_memalign 分配足够的内存，size（page_size：4096） 加上内存池本身和小块结构本身 	if (ret) { return NULL; } p-&amp;gt;max = (size &amp;lt; MP_MAX_ALLOC_FROM_POOL) ?</description>
    </item>
    
    <item>
      <title>请求池</title>
      <link>https://gao377020481.github.io/p/%E8%AF%B7%E6%B1%82%E6%B1%A0/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E8%AF%B7%E6%B1%82%E6%B1%A0/</guid>
      <description>请求池实现 同步阻塞请求池 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;unistd.h&amp;gt; #include &amp;lt;errno.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/socket.h&amp;gt;#include &amp;lt;netinet/in.h&amp;gt; #include &amp;lt;sys/epoll.h&amp;gt;#include &amp;lt;netdb.h&amp;gt;#include &amp;lt;arpa/inet.h&amp;gt; #include &amp;lt;pthread.h&amp;gt; #define DNS_SVR	&amp;#34;114.114.114.114&amp;#34;  #define DNS_HOST	0x01 #define DNS_CNAME	0x05  struct dns_header { unsigned short id; unsigned short flags; unsigned short qdcount; unsigned short ancount; unsigned short nscount; unsigned short arcount; }; struct dns_question { int length; unsigned short qtype; unsigned short qclass; char *qname; }; struct dns_item { char *domain; char *ip; }; int dns_create_header(struct dns_header *header) { if (header == NULL) return -1; memset(header, 0, sizeof(struct dns_header)); srandom(time(NULL)); header-&amp;gt;id = random(); header-&amp;gt;flags |= htons(0x0100); header-&amp;gt;qdcount = htons(1); return 0; } int dns_create_question(struct dns_question *question, const char *hostname) { if (question == NULL) return -1; memset(question, 0, sizeof(struct dns_question)); question-&amp;gt;qname = (char*)malloc(strlen(hostname) + 2); if (question-&amp;gt;qname == NULL) return -2; question-&amp;gt;length = strlen(hostname) + 2; question-&amp;gt;qtype = htons(1); question-&amp;gt;qclass = htons(1); const char delim[2] = &amp;#34;.</description>
    </item>
    
    <item>
      <title>锁</title>
      <link>https://gao377020481.github.io/p/%E9%94%81/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E9%94%81/</guid>
      <description>锁 自旋锁 当一个线程尝试去获取某一把锁的时候，如果这个锁此时已经被别人获取(占用)，那么此线程就无法获取到这把锁，该线程将会等待，间隔一段时间后会再次尝试获取。这种采用循环加锁 -&amp;gt; 等待的机制被称为自旋锁(spinlock)。
自旋锁的原理比较简单，如果持有锁的线程能在短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，它们只需要等一等(自旋)，等到持有锁的线程释放锁之后即可获取，这样就避免了用户进程和内核切换的消耗。
因为自旋锁避免了操作系统进程调度和线程切换，所以自旋锁通常适用在时间比较短的情况下。由于这个原因，操作系统的内核经常使用自旋锁。但是，如果长时间上锁的话，自旋锁会非常耗费性能，它阻止了其他线程的运行和调度。线程持有锁的时间越长，则持有该锁的线程将被 OS(Operating System) 调度程序中断的风险越大。如果发生中断情况，那么其他线程将保持旋转状态(反复尝试获取锁)，而持有该锁的线程并不打算释放锁，这样导致的是结果是无限期推迟，直到持有锁的线程可以完成并释放它为止。
解决上面这种情况一个很好的方式是给自旋锁设定一个自旋时间，等时间一到立即释放自旋锁。自旋锁的目的是占着CPU资源不进行释放，等到获取锁立即进行处理。但是如何去选择自旋时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！
在计算任务轻的情况下使用自旋锁可以显著提升速度，这是因为线程切换的开销大于等锁的开销，但是计算任务重的话自旋锁的等待时间就成为主要的开销了。
互斥锁 互斥锁实际是一个互斥量，为获得互斥锁的线程会挂起，这就涉及到线程切换的开销，计算任务重的情况下会比较适合使用。
读写锁 读写锁即只能由一人写但可以由多人读的锁，适用于读操作很多但写操作很少的情况下。
原子操作 多线程下使用原子操作确保我们的操作不会被其他线程参与，一般内联汇编 memory 内存屏障，只允许这一缓存写回内存，确保多线程安全。
多进程下对共享内存的操作使用内联汇编lock，锁住总线，同一时刻只允许一个进程通过总线操作内存。
粒度大小排序
互斥锁 &amp;gt; 自旋锁 &amp;gt; 读写锁 &amp;gt; 原子操作
代码实现 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;pthread.h&amp;gt;#include &amp;lt;unistd.h&amp;gt; #include &amp;lt;sys/mman.h&amp;gt; #define THREAD_SIZE 10  int count = 0; pthread_mutex_t mutex; pthread_spinlock_t spinlock; pthread_rwlock_t rwlock; // MOV dest, src; at&amp;amp;t // MOV src, dest; x86  int inc(int *value, int add) { int old; __asm__ volatile ( //lock 锁住总线 只允许一个cpu操作内存（通过总线）确保多进程安全  &amp;#34;lock; xaddl %2, %1;&amp;#34; // &amp;#34;lock; xchg %2, %1, %3;&amp;#34;  : &amp;#34;=a&amp;#34; (old) : &amp;#34;m&amp;#34; (*value), &amp;#34;a&amp;#34; (add) : &amp;#34;cc&amp;#34;, &amp;#34;memory&amp;#34; //memory 内存屏障，只允许这一缓存写回内存，确保多线程安全  ); return old; } // void *func(void *arg) { int *pcount = (int *)arg; int i = 0; while (i++ &amp;lt; 100000) { #if 0//无锁 (*pcount) ++; #elif 0// 互斥锁版本  pthread_mutex_lock(&amp;amp;mutex); (*pcount) ++; pthread_mutex_unlock(&amp;amp;mutex); #elif 0// 互斥锁非阻塞版本  if (0 !</description>
    </item>
    
    <item>
      <title>简易http客户端(C posix API)</title>
      <link>https://gao377020481.github.io/p/http%E5%AE%A2%E6%88%B7%E7%AB%AF/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/http%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid>
      <description>HTTP 实现http客户端程序
基础 HTTP使用TCP连接
HTTP报文：
 
实现 域名到ip地址转换(dns) 直接调用api进行转换比较简单：
char * host_to_ip(const char* hostname) { struct hostent *host_entry = gethostbyname(hostname); if(host_entry) { return inet_ntoa(*(struct in_addr*)*host_entry -&amp;gt; h_addr_list); } return NULL; } host_entry存储了dns请求的接收，从中取出第一个ip地址并将点分十进制转换为字符串返回
创建TCP套接字（建立连接） posix api创建
int http_create_socket(char *ip) { int sockfd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in sin = {0}; sin.sin_family = AF_INET; sin.sin_port = htons(80); sin.sin_addr.s_addr = inet_addr(ip); if(0 != connect(sockfd, (struct sockaddr*)&amp;amp;sin, sizeof(struct sockaddr_in))) { return -1; } fcntl(sockfd, F_SETFL, O_NONBLOCK); return sockfd; } fcntl(sockfd, F_SETFL, O_NONBLOCK);这个函数用于设置该套接字io为非阻塞</description>
    </item>
    
    <item>
      <title>DNS协议解析</title>
      <link>https://gao377020481.github.io/p/dns%E5%8D%8F%E8%AE%AE%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/dns%E5%8D%8F%E8%AE%AE%E8%A7%A3%E6%9E%90/</guid>
      <description>DNS Domain Name System 域名系统，是一个分布式数据库，用于映射IP与域名
每级域名长度限制为63，总长度限制为253，使用TCP UDP端口53
DNS分层 顶级域：com org等 第二级域：baidu google等 第三级域：www edu等
域名解析 静态映射：在本机上配置域名和ip映射并直接使用
动态映射：使用DNS域名解析系统，在DNS服务器上配置ip到域名的映射
域名服务器 根域名服务器： 共a-m十三台（十三个ip）但拥有很多镜像服务器，镜像与本体使用同一个ip，存有顶级域名服务器的ip 顶级域名服务器：管理在该顶级域名服务器下注册的二级域名 权限域名服务器：一个区域的域名解析 本地域名服务器：处理本地的请求，保存本地的映射
域名解析方式 迭代查询：本机请求本地域名服务器，本地域名服务器开始迭代的查询各个层级服务器，先查询根获得顶级的ip然后根据获得的ip查询顶级在获得区域的ip依次迭代查到请求的映射
递归查询：递归查询时只发出一次请求然后等待接收到最终结果，在上面的步骤中本机使用的就是递归查询
协议报文格式 dns_dp dns_dp dns_dp dns_dp
具体查看文档
DNS client UDP编程 首先需要自己定义数据结构用于存储dns报文
struct dns_header{ unsigned short id; unsigned short flags; unsigned short questions; unsigned short answer; unsigned short authority; unsigned short additional; }; struct dns_question { int length; unsigned short qtype; unsigned short qclass; unsigned char *name; }; 这里只需要question和header是因为我们作为client只实现发送A请求也就是获取域名的ipv4地址，在实现中header的授权码和附加码都不需要使用只需要使用questions id和flags即可</description>
    </item>
    
    <item>
      <title>简易Tcp服务器</title>
      <link>https://gao377020481.github.io/p/%E7%AE%80%E6%98%93tcp%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/%E7%AE%80%E6%98%93tcp%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>Tcp服务器 一请求一线程 首先说明问题： 已请求一线程能承载的请求数量极少，posix标准线程8M，请求数量多时极其占用内存
简单实现 实现一请求一线程很简单：
#define BUFFER_SIZE 1024 void *client_routine(void *arg) { int clientfd = *(int *) arg; while(1) { char buffer[BUFFER_SIZE] = {0}; int len = recv(clientfd, buffer, BUFFER_SIZE, 0); if(len &amp;lt;0 ) { close(clientfd); break; } else if(len ==0 ) { close(clientfd); break; } else{ printf(&amp;#34;Recv: %s, %d btye(s) from %d\n&amp;#34;, buffer, len, clientfd); } } } int main(int argc, char *argv[]) { if(argc &amp;lt;2) return -1; int port = atoi(argv[1]); int sockfd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in addr; memset(&amp;amp;addr, 0, sizeof(struct sockaddr_in)); addr.</description>
    </item>
    
    <item>
      <title>Mysql基本知识</title>
      <link>https://gao377020481.github.io/p/mysql%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/mysql%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</guid>
      <description>MYSQL mysql安装与配置 在虚拟机上安装mysql,使用apt-get install就可以 这里我只检索到了mysql-server-5.7就安装了5.7
在本地win10上安装mysqlbench用于连接虚拟机的mysql服务器 这里使用网络连接，可能是因为mysql版本的原因，本来应该在/etc/mysql中的my.cnf文件中显式的配置有基本信息，我只需要修改部分，但5.7在/etc/mysql/mysql.conf.d/mysqld.cnf,在它的基础上修改对应的bind-address为0.0.0.0保证回环地址可访问：
# # The MySQL database server configuration file. # # You can copy this to one of: # - &amp;#34;/etc/mysql/my.cnf&amp;#34; to set global options, # - &amp;#34;~/.my.cnf&amp;#34; to set user-specific options. # # One can use all long options that the program supports. # Run program with --help to get a list of available options and with # --print-defaults to see which it would actually understand and use.</description>
    </item>
    
    <item>
      <title>ubuntu-server虚拟机配置</title>
      <link>https://gao377020481.github.io/p/ubuntu-server%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gao377020481.github.io/p/ubuntu-server%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/</guid>
      <description>ubuntu-server虚拟机配置 Sh配置 安装完ubuntu后先配置sh这样可以通过xshell连接 只需要：
sudo apt-get install openssh-server ssh即可 Samba配置 然后安装samba
sudo apt-get install samba 创建share文件夹
cd /home sudo mkdir share sudo chmod 777 share 然后在/etc/samba里配置smb.conf 文件 在文件尾部添加：
[share] comment = My Samba path = /home/gao/share browseable = yes writeable = yes 然后设置密码
sudo smbpasswd -a gao 然后去主机上映射盘符就可以方便的访问 在文件框内输入\192.168.134.xxx 也就是虚拟机ip就可以 把share映射为盘符
gcc配置 换apt阿里源：
cd /etc/apt sudo mv source.list source.list.back sudo vim source.list 改为：
deb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-properties deb http://mirrors.</description>
    </item>
    
  </channel>
</rss>
